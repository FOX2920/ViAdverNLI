// Dataset data sáº½ Ä‘Æ°á»£c thÃªm tá»« page.tsx 

// Dataset analysis data tá»« page.tsx

// Complexity evaluation data for reasoning analysis
export const complexityEvaluationData = [
  {
    round: "R1",
    split: "dev",
    lcs_ratio: 44.52,
    nwr: 34.36,
    jaccard: 15.00,
    lexical_overlap: 67.18,
    unique_overlap: 65.64,
    tfidf_cosine: 47.68,
    semantic_similarity: 74.64,
    num_sent_ctx: 11.02,
    num_sent_clm: 2.04,
    len_ctx: 295.35,
    len_clm: 42.29
  },
  {
    round: "R1",
    split: "test",
    lcs_ratio: 44.68,
    nwr: 34.13,
    jaccard: 14.80,
    lexical_overlap: 67.42,
    unique_overlap: 65.87,
    tfidf_cosine: 47.34,
    semantic_similarity: 74.41,
    num_sent_ctx: 11.28,
    num_sent_clm: 2.04,
    len_ctx: 300.86,
    len_clm: 42.47
  },
  {
    round: "R1",
    split: "train",
    lcs_ratio: 41.36,
    nwr: 38.07,
    jaccard: 16.21,
    lexical_overlap: 63.52,
    unique_overlap: 61.93,
    tfidf_cosine: 47.10,
    semantic_similarity: 75.31,
    num_sent_ctx: 9.86,
    num_sent_clm: 2.06,
    len_ctx: 249.07,
    len_clm: 45.39
  },
  {
    round: "R2",
    split: "dev",
    lcs_ratio: 33.73,
    nwr: 47.21,
    jaccard: 14.70,
    lexical_overlap: 54.45,
    unique_overlap: 52.79,
    tfidf_cosine: 42.65,
    semantic_similarity: 75.25,
    num_sent_ctx: 8.72,
    num_sent_clm: 2.12,
    len_ctx: 243.44,
    len_clm: 49.45
  },
  {
    round: "R2",
    split: "test",
    lcs_ratio: 34.75,
    nwr: 46.28,
    jaccard: 15.29,
    lexical_overlap: 55.24,
    unique_overlap: 53.72,
    tfidf_cosine: 43.91,
    semantic_similarity: 75.85,
    num_sent_ctx: 8.42,
    num_sent_clm: 2.11,
    len_ctx: 238.32,
    len_clm: 49.61
  },
  {
    round: "R2",
    split: "train",
    lcs_ratio: 34.35,
    nwr: 45.38,
    jaccard: 15.87,
    lexical_overlap: 56.42,
    unique_overlap: 54.62,
    tfidf_cosine: 44.32,
    semantic_similarity: 76.08,
    num_sent_ctx: 9.34,
    num_sent_clm: 2.10,
    len_ctx: 257.46,
    len_clm: 53.46
  },
  {
    round: "R3",
    split: "dev",
    lcs_ratio: 32.70,
    nwr: 49.69,
    jaccard: 13.20,
    lexical_overlap: 51.87,
    unique_overlap: 50.31,
    tfidf_cosine: 40.24,
    semantic_similarity: 73.77,
    num_sent_ctx: 10.70,
    num_sent_clm: 2.07,
    len_ctx: 283.43,
    len_clm: 48.78
  },
  {
    round: "R3",
    split: "test",
    lcs_ratio: 32.04,
    nwr: 50.44,
    jaccard: 12.93,
    lexical_overlap: 51.19,
    unique_overlap: 49.56,
    tfidf_cosine: 39.78,
    semantic_similarity: 73.18,
    num_sent_ctx: 10.67,
    num_sent_clm: 2.07,
    len_ctx: 282.54,
    len_clm: 48.94
  },
  {
    round: "R3",
    split: "train",
    lcs_ratio: 36.05,
    nwr: 46.82,
    jaccard: 12.45,
    lexical_overlap: 54.54,
    unique_overlap: 53.18,
    tfidf_cosine: 40.63,
    semantic_similarity: 72.52,
    num_sent_ctx: 10.93,
    num_sent_clm: 2.06,
    len_ctx: 284.08,
    len_clm: 42.57
  }
];

export const complexityMetricsDefinition = [
  { metric: "lcs_ratio (%)", definition: "Tá»· lá»‡ LCS so vá»›i Ä‘á»™ dÃ i cá»§a claim_tokens, (%)" },
  { metric: "nwr (%)", definition: "New Word Ratio: % tá»« trong claim khÃ´ng cÃ³ trong context" },
  { metric: "jaccard (%)", definition: "Jaccard Similarity: Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng táº­p tá»« giá»¯a context vÃ  claim, (%)" },
  { metric: "lexical_overlap (%)", definition: "Tá»· lá»‡ token trong claim xuáº¥t hiá»‡n trong context, (%)" },
  { metric: "unique_overlap (%)", definition: "Tá»· lá»‡ tá»« duy nháº¥t cá»§a claim cÅ©ng cÃ³ trong context, (%)" },
  { metric: "tfidf_cosine (%)", definition: "Cosine similarity giá»¯a vector TFâ€“IDF cá»§a context vÃ  claim, (%)" },
  { metric: "semantic_similarity (%)", definition: "Cosine similarity giá»¯a embeddings SBERT cá»§a context vÃ  claim, (%)" },
  { metric: "num_sent_ctx", definition: "Sá»‘ cÃ¢u trong context (Ä‘áº¿m thÃ´ theo dáº¥u cháº¥m \".\")" },
  { metric: "num_sent_clm", definition: "Sá»‘ cÃ¢u trong claim" },
  { metric: "len_ctx", definition: "Sá»‘ token (tá»«) cá»§a context" },
  { metric: "len_clm", definition: "Sá»‘ token (tá»«) cá»§a claim" }
];

export const dataSourcesBreakdown = {
  Wikipedia: { total: 9973, percentage: 46.9, rounds: { R1: 2601, R2: 2150, R3: 5222 } },
  VnExpress: { total: 6023, percentage: 28.3, rounds: { R1: 2746, R2: 1155, R3: 2122 } },
  "BÃ¡o Lao Äá»™ng": { total: 1484, percentage: 7.0, rounds: { R1: 0, R2: 389, R3: 1095 } },
  "BÃ¡o PhÃ¡p Luáº­t": { total: 1123, percentage: 5.3, rounds: { R1: 0, R2: 630, R3: 493 } },
  "BÃ¡o ChÃ­nh Phá»§": { total: 1114, percentage: 5.2, rounds: { R1: 0, R2: 614, R3: 500 } },
  "BÃ¡o NhÃ¢n DÃ¢n": { total: 1088, percentage: 5.1, rounds: { R1: 0, R2: 566, R3: 522 } },
  "Thanh NiÃªn": { total: 457, percentage: 2.1, rounds: { R1: 0, R2: 457, R3: 0 } },
};

// Detailed statistics per round from paper Table tab:viadvernli-stats
export const detailedStatsPerRound = [
  {
    round: "R1",
    numSamples: 5347,
    avgClaimLen: 44.02,
    minClaimLen: 8,
    maxClaimLen: 126,
    avgContextLen: 271.46,
    minContextLen: 33,
    maxContextLen: 1935,
    vocabSize: 21022
  },
  {
    round: "R2", 
    numSamples: 5961,
    avgClaimLen: 51.50,
    minClaimLen: 12,
    maxClaimLen: 179,
    avgContextLen: 249.19,
    minContextLen: 50,
    maxContextLen: 1422,
    vocabSize: 21054
  },
  {
    round: "R3",
    numSamples: 9954,
    avgClaimLen: 44.86,
    minClaimLen: 10,
    maxClaimLen: 198,
    avgContextLen: 283.68,
    minContextLen: 62,
    maxContextLen: 1783,
    vocabSize: 25697
  }
];

export const dataOriginDistribution = [
  { origin: "VNEXPRESS", count: 2746, round: "R1" },
  { origin: "WIKI", count: 2601, round: "R1" },
  { origin: "WIKI", count: 2150, round: "R2" },
  { origin: "VNEXPRESS", count: 1155, round: "R2" },
  { origin: "BÃO PHÃP LUáº¬T", count: 630, round: "R2" },
  { origin: "BÃO CHÃNH PHá»¦", count: 614, round: "R2" },
  { origin: "BÃO NHÃ‚N DÃ‚N", count: 566, round: "R2" },
  { origin: "THANHNIEN.VN", count: 457, round: "R2" },
  { origin: "BÃO LAO Äá»˜NG", count: 389, round: "R2" },
  { origin: "WIKI", count: 5222, round: "R3" },
  { origin: "VNEXPRESS", count: 2122, round: "R3" },
  { origin: "BÃO LAO Äá»˜NG", count: 1095, round: "R3" },
  { origin: "BÃO NHÃ‚N DÃ‚N", count: 522, round: "R3" },
  { origin: "BÃO CHÃNH PHá»¦", count: 500, round: "R3" },
  { origin: "BÃO PHÃP LUáº¬T", count: 493, round: "R3" }
];

export const splitDistribution = [
  { split: "dev", nei: 642, refuted: 377, supported: 201, round: "R1" },
  { split: "test", nei: 674, refuted: 354, supported: 193, round: "R1" },
  { split: "train", nei: 548, refuted: 1004, supported: 1354, round: "R1" },
  { split: "dev", nei: 630, refuted: 473, supported: 384, round: "R2" },
  { split: "test", nei: 645, refuted: 473, supported: 370, round: "R2" },
  { split: "train", nei: 822, refuted: 1052, supported: 1112, round: "R2" },
  { split: "dev", nei: 527, refuted: 576, supported: 712, round: "R3" },
  { split: "test", nei: 535, refuted: 569, supported: 712, round: "R3" },
  { split: "train", nei: 2367, refuted: 2058, supported: 1898, round: "R3" }
];

export const jaccardSimilarity = [
  { round: "R1", avgJaccard: 0.1621, minJaccard: 0.0094, maxJaccard: 0.5714 },
  { round: "R2", avgJaccard: 0.1587, minJaccard: 0, maxJaccard: 0.587 },
  { round: "R3", avgJaccard: 0.1245, minJaccard: 0, maxJaccard: 0.5449 }
];

// Dataset comparison data from comparison_report.md
export const datasetComparison = [
  {
    name: "ViAdverNLI (R1-R3)",
    description: "benchmark NLI adversarial",
    samples: "~21.3k cáº·p",
    dataType: "premise/hypothesis",
    labels: "3 nhÃ£n NLI",
    textLength: "premise ~24 tá»«, hyp ~12-15 tá»«", 
    method: "human+model loop",
    accuracy: "~58% (SOTA)",
    highlight: "Adversarial 3 rounds",
    color: "bg-red-50 border-red-200 text-red-800"
  },
  {
    name: "ViNLI", 
    description: "NLI corpus Ä‘áº§u tiÃªn",
    samples: ">30k cáº·p",
    dataType: "premise/hypothesis",
    labels: "3 nhÃ£n NLI",
    textLength: "premise ~24.5 tá»«, hyp ~18.1 tá»«",
    method: "manual 5 annotator",
    accuracy: "~79% (SOTA)",
    highlight: "Baseline NLI",
    color: "bg-blue-50 border-blue-200 text-blue-800"
  },
  {
    name: "ViWikiFC",
    description: "Wikipedia-based fact-checking", 
    samples: ">20k cáº·p",
    dataType: "claim + evidence",
    labels: "3 nhÃ£n FEVER",
    textLength: "claim ~15-20 tá»«, evidence ~20-40 tá»«",
    method: "manual FEVER style",
    accuracy: "~79% (SOTA)",
    highlight: "Wikipedia source",
    color: "bg-green-50 border-green-200 text-green-800"
  },
  {
    name: "ViFactCheck",
    description: "news fact-check benchmark",
    samples: "7,232 cáº·p", 
    dataType: "claim + evidence",
    labels: "3 nhÃ£n",
    textLength: "claim ~12-15 tá»«, evidence ~30-50 tá»«",
    method: "manual expert",
    accuracy: "~62% (SOTA)",
    highlight: "News articles",
    color: "bg-yellow-50 border-yellow-200 text-yellow-800"
  },
  {
    name: "ISE-DSC01",
    description: "competition dataset",
    samples: "~49.7k cáº·p",
    dataType: "claim + context", 
    labels: "3 nhÃ£n",
    textLength: "claim ~10-20 tá»«, context ~50-100 tá»«",
    method: "auto+manual",
    accuracy: "~84% (SOTA)",
    highlight: "Largest dataset",
    color: "bg-purple-50 border-purple-200 text-purple-800"
  }
];

export const viadvernliHighlights = [
  {
    title: "Äá»™ khÃ³ cao",
    description: "MÃ´ hÃ¬nh SOTA chá»‰ Ä‘áº¡t ~58% accuracy, tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c dataset khÃ¡c (~79â€“84%)",
    icon: "âš¡",
    impact: "Thá»­ thÃ¡ch mÃ´ hÃ¬nh máº¡nh nháº¥t"
  },
  {
    title: "Quy trÃ¬nh adversarial 3 vÃ²ng", 
    description: "Duy nháº¥t sá»­ dá»¥ng human-and-model-in-the-loop Ä‘á»ƒ thu tháº­p máº«u gÃ¢y báº«y cho mÃ´ hÃ¬nh",
    icon: "ğŸ”„",
    impact: "PhÆ°Æ¡ng phÃ¡p Ä‘á»™c Ä‘Ã¡o"
  },
  {
    title: "Äa dáº¡ng ngÃ´n ngá»¯",
    description: "Tá»· lá»‡ trÃ¹ng tá»« tháº¥p, nhiá»u cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c biá»‡t, bao gá»“m áº©n dá»¥, thay Ä‘á»•i chi tiáº¿t nhá»", 
    icon: "ğŸŒ",
    impact: "Linguistic diversity cao"
  },
  {
    title: "GiÃ¡ trá»‹ huáº¥n luyá»‡n",
    description: "Khi huáº¥n luyá»‡n trÃªn ViAdverNLI, mÃ´ hÃ¬nh cáº£i thiá»‡n hiá»‡u quáº£ tá»•ng quÃ¡t trÃªn cÃ¡c dataset NLI khÃ¡c",
    icon: "ğŸ“ˆ", 
    impact: "Cross-dataset improvement"
  },
  {
    title: "Bá»• sung khoáº£ng trá»‘ng",
    description: "Cung cáº¥p benchmark NLI adversarial cho tiáº¿ng Viá»‡t, má»Ÿ hÆ°á»›ng nghiÃªn cá»©u robust NLI vÃ  fact-checking",
    icon: "ğŸ¯",
    impact: "Research gap filling"
  }
]; 